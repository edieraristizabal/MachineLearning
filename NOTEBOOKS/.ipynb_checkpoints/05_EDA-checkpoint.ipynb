{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "CURSO: Análisis Geoespacial (Sem02-2019)                                                                                   \n",
    "Profesor: Edier Aristizábal (evaristizabalg@unal.edu.co)                                                                   \n",
    "Curso website: https://unvirtual.medellin.unal.edu.co/course/view.php?id=579"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05: Selección de variables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Luego de realizar la limpieza y ajustes sobre los datos de entrada, se debe seleccionar las mejores variables predictoras, que conformarán los *features* del modelo.\n",
    "\n",
    "Es importante tener en cuenta en esta fase que existen diferentes métodos estadísticos que ayudan a identificar dichas variables, sin embargo el mejor método es una buena comprensión del problema y de las variables a utilizar.\n",
    "\n",
    "A continuación se describen inicialmente los métodos para conocer cada una de las variables, y su relación con las demás variables. Y finalmente se presentan métodos para identificar de forma automática las mejores variables predictoras. Recuerde que dichos métodos no son mas que herramientas estadísticas que le pueden proporcionar informacion importante, pero la mejor selección la debe hacer el usuario considerando toda la información obtenida de las diferentes variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerias"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Importar los ficheros necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from osgeo import gdal\n",
    "#import statsmodels.graphics.api as smg\n",
    "from feature_selector import FeatureSelector\n",
    "%matplotlib notebook\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar datos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "importar en python los mapas raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ruta='G:\\My Drive\\ANALISIS ESPACIAL APLICADO\\datos\\la_miel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = gdal.Open(ruta+'\\Aspecto.tif')\n",
    "raster = file.GetRasterBand(1)\n",
    "aspecto = raster.ReadAsArray()\n",
    "aspecto=np.where(aspecto==-999,np.nan,aspecto)\n",
    "plt.imshow(aspecto)\n",
    "print('Dimensiones de la matriz del mapa de aspecto:', aspecto.shape)\n",
    "aspecto_vector=aspecto.ravel()\n",
    "aspecto_vector_MenM=aspecto_vector[~np.isnan(aspecto_vector)]\n",
    "print('Dimensiones del vector de aspecto:',aspecto_vector_MenM.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Antes de generar el dataframe con las diferentes variables, es necesario entonces importar todas las variables y realizar los ajustes que sean necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = gdal.Open(ruta+'\\Buffer_Drenajes.tif')\n",
    "raster = file.GetRasterBand(1)\n",
    "drenajes = raster.ReadAsArray()\n",
    "drenajes=np.where(drenajes==-999,np.nan,drenajes)\n",
    "plt.imshow(drenajes)\n",
    "plt.colorbar();\n",
    "drenajes_vector=drenajes.ravel()\n",
    "drenajes_vector_MenM=drenajes_vector[~np.isnan(drenajes_vector)]\n",
    "print('Dimensiones del vector de drenajes:',drenajes_vector_MenM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = gdal.Open(ruta+'\\Curvatura_Categorica.tif')\n",
    "raster = file.GetRasterBand(1)\n",
    "curvatura = raster.ReadAsArray()\n",
    "curvatura = np.where(curvatura==-999,np.nan,curvatura)\n",
    "plt.imshow(curvatura)\n",
    "plt.colorbar();\n",
    "curvatura_vector=curvatura.ravel()\n",
    "curvatura_vector_MenM=curvatura_vector[~np.isnan(curvatura_vector)]\n",
    "print('Dimensiones del vector de curvatura:',curvatura_vector_MenM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = gdal.Open(ruta+'\\FlujoAcumulado.tif')\n",
    "raster = file.GetRasterBand(1)\n",
    "flujo = raster.ReadAsArray()\n",
    "flujo = np.where(flujo==-999,np.nan,flujo)\n",
    "plt.imshow(flujo)\n",
    "plt.colorbar();\n",
    "flujo_vector=flujo.ravel()\n",
    "flujo_vector_MenM=flujo_vector[~np.isnan(flujo_vector)]\n",
    "print('Dimensiones del vector de flujo:',flujo_vector_MenM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = gdal.Open(ruta+'\\Geologia_Superficial.tif')\n",
    "raster = file.GetRasterBand(1)\n",
    "geologia = raster.ReadAsArray()\n",
    "geologia = np.where(geologia==-999,np.nan,geologia)\n",
    "plt.imshow(geologia)\n",
    "plt.colorbar();\n",
    "geologia_vector=geologia.ravel()\n",
    "geologia_vector_MenM=geologia_vector[~np.isnan(geologia_vector)]\n",
    "print('Dimensiones del vector de geología:',geologia_vector_MenM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = gdal.Open(ruta+'\\Pendiente.tif')\n",
    "raster = file.GetRasterBand(1)\n",
    "pendiente = raster.ReadAsArray()\n",
    "pendiente = np.where(pendiente==-999,np.nan,pendiente)\n",
    "plt.imshow(pendiente)\n",
    "plt.colorbar();\n",
    "pendiente_vector=pendiente.ravel()\n",
    "pendiente_vector_MenM=pendiente_vector[~np.isnan(pendiente_vector)]\n",
    "print('Dimensiones del vector de pendiente:',pendiente_vector_MenM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = gdal.Open(ruta+'\\Rugosidad.tif')\n",
    "raster = file.GetRasterBand(1)\n",
    "rugosidad = raster.ReadAsArray()\n",
    "rugosidad = np.where(rugosidad==-999,np.nan,rugosidad)\n",
    "plt.imshow(rugosidad)\n",
    "plt.colorbar();\n",
    "rugosidad_vector=rugosidad.ravel()\n",
    "rugosidad_vector_MenM=rugosidad_vector[~np.isnan(rugosidad_vector)]\n",
    "print('Dimensiones del vector de rugosidad:',rugosidad_vector_MenM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = gdal.Open(ruta+'\\SPI.tif')\n",
    "raster = file.GetRasterBand(1)\n",
    "SPI = raster.ReadAsArray()\n",
    "SPI = np.where(SPI==-999,np.nan,SPI)\n",
    "plt.imshow(SPI)\n",
    "plt.colorbar();\n",
    "SPI_vector=SPI.ravel()\n",
    "SPI_vector_MenM=SPI_vector[~np.isnan(SPI_vector)]\n",
    "print('Dimensiones del vector de SPI:',SPI_vector_MenM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = gdal.Open(ruta+'\\STI.tif')\n",
    "raster = file.GetRasterBand(1)\n",
    "STI= raster.ReadAsArray()\n",
    "STI = np.where(STI==-999,np.nan,STI)\n",
    "plt.imshow(STI)\n",
    "plt.colorbar();\n",
    "STI_vector=STI.ravel()\n",
    "STI_vector_MenM=STI_vector[~np.isnan(STI_vector)]\n",
    "print('Dimensiones del vector de STI:',STI_vector_MenM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = gdal.Open(ruta+'\\TWI.tif')\n",
    "raster = file.GetRasterBand(1)\n",
    "TWI = raster.ReadAsArray()\n",
    "msk=np.where(TWI==-999.0,0,1)\n",
    "TWI = np.where(TWI==-999,np.nan,TWI)\n",
    "plt.imshow(TWI)\n",
    "plt.colorbar();\n",
    "TWI_vector=TWI.ravel()\n",
    "TWI_vector_MenM=TWI_vector[~np.isnan(TWI_vector)]\n",
    "print('Dimensiones del vector de TWI:',TWI_vector_MenM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = gdal.Open(ruta+'\\Inventario_MenM.tif')\n",
    "raster = file.GetRasterBand(1)\n",
    "inventario = raster.ReadAsArray()\n",
    "inventario=np.where(msk==0,np.nan,inventario)\n",
    "plt.imshow(inventario)\n",
    "inventario_vector=inventario.ravel()\n",
    "inventario_vector_MenM=inventario_vector[~np.isnan(inventario_vector)]\n",
    "inventario_vector_MenM.shape\n",
    "print('Dimensiones del vector de inventario:',inventario_vector_MenM.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con cada uno de los vectores de las variables independientes y dependiente, se conforma un diccionario, para luego formar un DataFrame con todas las variables, y posteriormente armar un DataFrame solo con las variables predictoras (X) y un vector con la variable dependiente (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d={'inventario':inventario_vector_MenM,'drenajes':drenajes_vector_MenM,'pendiente':pendiente_vector_MenM,'geologia':geologia_vector_MenM,'flujo':flujo_vector_MenM,'aspecto':aspecto_vector_MenM,\n",
    "   'curvatura':curvatura_vector_MenM,'rugosidad':rugosidad_vector_MenM,'TWI':TWI_vector_MenM,'STI':STI_vector_MenM,'SPI':SPI_vector_MenM}\n",
    "df = pd.DataFrame(d)\n",
    "print(list(df.columns))\n",
    "X=df.drop('inventario',axis=1)\n",
    "print(X.columns)\n",
    "print('Número de filas y columnas de los features:', X.shape)\n",
    "y=df['inventario']\n",
    "print('Número de filas del label:',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante tambien crear una matriz solo con las variables predictoras continuas, ya que muchso de los métodos a utilizar solo trabajan con este tipo de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_cont=X.drop(['geologia'],1)\n",
    "X_array_cont=X.values\n",
    "X_cont.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para obtener los estadísticos básicos de todas las variables continuas se utiliza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_cont.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema a resolver corresponde a un método supervisado tipo clasificación, donde la variable dependiente es categórica dicotómica (la ocurrencia o no de movimientos en masa en una celda), por lo tanto es útil conocer el número de celdas con y sin MenM que permitirá entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber la media de cada variable independiente de acuerdo con la variable dependiente. Para esto utilizamos el DataFrame inicial (df) dodne se agruparon todas las variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "media=df.groupby('inventario').mean()\n",
    "print(media)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente para conocer el comportamiento bivariado de todas las variables se utiliza la matriz de scattering con Panda. Sin embargo tenga en cuenta que este método toma tiempo en ejecutarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(X_cont, alpha = 0.3, figsize = (14,10), diagonal='kde');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería de *Seaborn* es similar a Matplotlib, sin embargo presenta gráficas con mejores diseños. La matriz de scattering utilizando *Seaborn* se genera de la siguiente manera, y de forma similar al caso anterior toma tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='inventario');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis univariado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar el histograma de una sola variable se puede utilizar el siguiente código con el método *hist*.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.pendiente.hist()\n",
    "plt.title('Histograma de Pendiente')\n",
    "plt.xlabel('Pendiente')\n",
    "plt.ylabel('Frecuencia');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la librearía *Seaborn* se puede generar el *displot* de las diferentes variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(X['aspecto'],color='g');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar el histograma de las variables continuas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_cont.plot(kind='density', subplots=True, layout=(3,3), sharex=False, figsize=(10, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar el diagrama de caja de cada variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pendiente=X['pendiente']\n",
    "plt.boxplot(pendiente);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='pendiente', data=X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El diagrama tipo Violin brinda información similar al *boxplot*, sin embargo en algunos casos puede brindar información adicional sobre la distribución de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x='pendiente', data=X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Bivariado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis bivariado permite identificar asociación o correlación entre diferentes variables. Se utilizan las siguientes herramientas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x='pendiente', y='TWI', data=X, kind='scatter');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x='pendiente', y='flujo', data=X, kind='kde', color='g');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un análisis muy importante es la distribución de cada variable independiente en función de la variable dependiente. Distribuciones diferentes permite inferir que dicha variable puede ser buena predictora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente se construyen dos nuevos dataFrames filtrando entre celdas donde la variabel independiente es 1 y celdas donde es 0, en este caso CON y SIN movimientos en masa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sin=df[(df['inventario']==0)]\n",
    "data_con=df[(df['inventario']==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos dos DataFrames se pueden comparar las variables indepependientes en funcion de y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "data_sin['pendiente'].plot.kde(ax=ax, label='Sin MenM')\n",
    "data_con['pendiente'].plot.kde(ax=ax, label='Con MenM')\n",
    "ax.set_xlim(0,90)\n",
    "ax.set_xlabel('Pendiente (grados)', color='k', size=12)\n",
    "ax.set_ylabel('Densidad', color='k', size=12)\n",
    "ax.legend(loc=1, fontsize=10)\n",
    "ax.tick_params('y', colors='k', labelsize= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Multivariado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis multivariado permite analizar tres o mas variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"curvatura\", y=\"pendiente\", hue=\"inventario\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una etapa fundamental en el análisis multivariado de los datos es evaluar la correlación entre ellos. Para lo cual existen diferentes herramientas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de ellas es utilizando la librería *feature Selector* para todas las variables. Para lo cual es necesario inicialmente instanciar el método, y luego correr la función *indetify_collinear*, donde se debe precisar un umbral de correlación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = FeatureSelector(data = X, labels = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs.identify_collinear(correlation_threshold=0.5)\n",
    "correlated_features = fs.ops['collinear']\n",
    "correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fs.plot_collinear(plot_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener una tabla con las correlaciones se utiliza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs.record_collinear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librearía *statsmodel* también brinda herramientas para identificar y plotear la matriz de correlación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MatCorre=DataFrame(X.corr())\n",
    "smg.plot_corr(MatCorre, xnames=list(MatCorre.columns));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la libraría *Seaborn* también tiene una función para plotear la matriz, dodne a diferencia de las demas marca el valor de la correlación en cada celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "cor = X.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librearía de Feature-Selector tiene 5 funciones para seleccionar los mejores *features*, identificando y eliminando columnas utilizando como criterios los datos faltantes, las columnas con valores únicos que no le aportan al modelo, las columnas que sean correlacionables, y las columnas sin importancia o con muy baja. Para lo cual contiene las siguientes funciones:\n",
    "\n",
    "- identify_missing                                                                                                  \n",
    "- identify_single_unique                                                                                                 \n",
    "- identify_collinear                                                                                                       \n",
    "- identify_zero_importance                                                                                                 \n",
    "- identify_low_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las 3 primeras funciones ya fueron utilizadas en el libro anterior y en este libro. A continuación se presenta las dos ultimas funciones para identificar automáticamente la importancia de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fs.identify_zero_importance(task = 'classification', eval_metric = 'auc', \n",
    "                            n_iterations = 10, early_stopping = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para correr el gradiente *gradient boosting model* se reqeuire un *one hot encoding* de las variables independientes. Las cuales son guardadas en *base_features*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot_features = fs.one_hot_features\n",
    "base_features = fs.base_features\n",
    "print('There are %d original features' % len(base_features))\n",
    "print('There are %d one-hot features' % len(one_hot_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabla con todas las variables, incluidas a las que le fue aplicado el método *one hot encoding* se encuentra en *data_all*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs.data_all.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las variables que presenta un valor de cero (0) en la importancia se utiliza: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_importance_features = fs.ops['zero_importance']\n",
    "zero_importance_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede graficar el valor normalizado de importancia de todas las variables. Ademas es posible ingresar un umbral, en este caso 0.99, que señala que solo se muestren las variables que suman el 99% de la importancia total de todas las variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fs.plot_feature_importances(threshold = 0.99, plot_n = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien se puede obtener la tabla con el valor normalizado y el valor acumulado de todas las variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs.feature_importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien es posible generar una lista con el número de \"n\" variables mas importantes de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hundred_features = list(fs.feature_importances.loc[:3, 'feature'])\n",
    "one_hundred_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante tener en cuenta que este es un metodo probabilístico por lo cual cada corrida puede dar valores ligeramente diferentes.\n",
    "\n",
    "para identificar los feature que sumen el 99% de importancia, se utiliza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs.identify_low_importance(cumulative_importance = 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low importance features to remove are those that do not contribute to the specified cumulative importance. These are also available in the ops dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_importance_features = fs.ops['low_importance']\n",
    "low_importance_features[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables con *SelecktBest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data= pd.read_excel('G:\\My Drive\\ANALISIS ESPACIAL APLICADO\\datos\\Cuencas_torrencialidad.xlsx', sheet_name='Hoja2')\n",
    "X=data.drop(['Name', 'Flash flood record'],axis=1)\n",
    "y=data['Flash flood record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(mutual_info_regression, k=4)\n",
    "fit=selector.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = selector.scores_\n",
    "plt.rcParams[\"figure.figsize\"] = [12,8]\n",
    "plt.plot(scores)\n",
    "plt.xticks(np.arange(32),list(X.columns));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(fit.scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables con *Recursive Feature Elimination (RFE)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model=LogisticRegression()\n",
    "rfe=RFE(model,3)\n",
    "fit=rfe.fit(X,y)\n",
    "print(fit.n_features_)\n",
    "print(fit.support_)\n",
    "print(fit.ranking_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
