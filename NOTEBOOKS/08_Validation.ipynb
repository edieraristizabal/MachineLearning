{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CURSO**: *Machine Learning* en Geociencias<br />\n",
    "**Profesor**: Edier Aristizábal (evaristizabalg@unal.edu.co) <br />\n",
    "**Classroom code**: [wv4cglx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08: Validación Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *train-test-split*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algortimo es muy rapido y es ideal para grandes bases de datos en donde los datos de entrenamiento y validacion son lo suficientemente represetativos del problema. Debido a que es rapido se puede utilizar cona algoritmos complejos y lento para el entrenamiento. Una falencia del método es que puede generar alta varianza debido a grandes diferencias entre los datos de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "X,y=load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un agumento importante de este algoritmo es *random_state*, el cual permite obtener con el mismo numero la misma partición de datos aleatoria, para asegurar resultados similares. A continuacion se va a generar tres particiones, donde dos de ellas tiene el mismo valor semilla (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y, train_size=0.5, random_state=1)\n",
    "X2_train,X2_test, y2_train,y2_test = train_test_split(X,y, random_state=1)\n",
    "X3_train,X3_test, y3_train,y3_test = train_test_split(X,y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la matriz para entrenar: (379, 13)\n",
      "Dimensiones del vector para entrenar: (379,)\n",
      "Dimensiones de la matriz para validar: (127, 13)\n",
      "Dimensiones del vector para validar: (127,)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensiones de la matriz para entrenar:',X_train.shape)\n",
    "print('Dimensiones del vector para entrenar:',y_train.shape)\n",
    "print('Dimensiones de la matriz para validar:',X_test.shape)\n",
    "print('Dimensiones del vector para validar:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto la función *train_test_split* divide la base de datos en 75% para entrenamiento y 25% para validación. pero cone l argumento *test_size* se puede especificar otro valor para el tamno de lso datso de validacion entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(X_train,X2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar para los conjuntos con valor 1 las bases de datso aleatroias seleccioandas son exactamente iguales. En el caso doden se comapra con la seleccion aleatoria pero con semilla 2, las bases de datso no son iguales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(X_train,X3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion se puede implementar el modelo, en este caso Lasso, entrenarlo directamente y preguntar por el *score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7789410172622834"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression().fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada (*cross validation*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *K-fold*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método de *K-fold Cross Validation* permite obtener el desempeño del algoritmo con menor varianza que un particion sencilla de *train-test set split*. Este metodo divide lso datos en un número de K subconjuntos (k = 5 ó k = 10). Cada partición es denominada un *fold*. El algoritmo es entonces entrenado con K-1 subconjuntos y un subconjunto es utilizado para validar. Esto es k veces repetido por lo que se obtienen k valores de *score*. El algoritmo es por lo tanto entrenado y evaluado múltiples veces. Como resultado de esta función no se obtiene un modelo, ya que varios modelos son creados internamente, el propósito es sólamente evaluar que tan bien un algoritmo determinado va a generalizar con otros datos diferentes al entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76202909 0.8288083  0.4883423  0.82375273 0.58676533 0.74116246\n",
      " 0.70983959]\n",
      "0.7058142574151517\n",
      "0.11645325435580706\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=7, shuffle= True,random_state=1)\n",
    "model = LinearRegression()\n",
    "results = cross_val_score(model, X, y, cv=kfold, scoring='r2')\n",
    "print(results)\n",
    "print(results.mean())\n",
    "print(results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presenta la función *cross_validate*, la cual difiere de *cross_val_score* ya que permite definir múltiples métricas para estimar el ajuste, adicionalmente las salidas de la función son diferentes como se observa a continuación. Por defecto la función *cross_val_score* genera 3 particiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.29299998, 0.00199986, 0.00199986, 0.00099993, 0.00099993]),\n",
       " 'score_time': array([0.00300002, 0.00099993, 0.00100017, 0.00100017, 0.00099993]),\n",
       " 'test_score': array([ 0.66089569,  0.74094893,  0.62923672,  0.08530169, -0.17029513]),\n",
       " 'train_score': array([0.74372716, 0.72395587, 0.68988726, 0.84024816, 0.73384871])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ridge = cross_validate(Ridge(),X,y,return_train_score=True,cv=5)\n",
    "results_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.746333431797385\n",
      "Test scores: 0.38921758241023985\n"
     ]
    }
   ],
   "source": [
    "test_scores = results_ridge['test_score']\n",
    "train_scores = results_ridge['train_score']\n",
    "print('Train scores:', np.mean(train_scores))\n",
    "print('Test scores:', np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.10900021, 0.00200033, 0.00199986, 0.00099993, 0.00200009]),\n",
       " 'score_time': array([0.00099993, 0.00099993, 0.00099993, 0.00099993, 0.00099993]),\n",
       " 'test_score': array([0.56156843, 0.63385562, 0.33456629, 0.35466066, 0.27459294]),\n",
       " 'train_score': array([0.69205313, 0.66722484, 0.62206251, 0.77992825, 0.68385778])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lasso = cross_validate(Lasso(),X,y,return_train_score=True,cv=5)\n",
    "results_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.6890252995484658\n",
      "Test scores: 0.431848787926522\n"
     ]
    }
   ],
   "source": [
    "test_scores = results_lasso['test_score']\n",
    "train_scores = results_lasso['train_score']\n",
    "print('Train scores:', np.mean(train_scores))\n",
    "print('Test scores:', np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Stratified Kfold*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En problemas de regresión scikit-learn utiliza por defecto el k-fold, pero para problemas de clasificación scikit-learn utiliza *stratified k-fold cross-validation*, en donde los datos son divididos en igual proporción de las clases en la totalidad de datos, es decir preservando el porcentaje de observaciones en cada clase. Por esta razón es un buena estrategia para datos imbalanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9381785777147649\n",
      "0.018696245922007717\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "data= pd.read_excel('G:\\My Drive\\ANALISIS ESPACIAL APLICADO\\datos\\Cuencas_torrencialidad.xlsx', sheet_name='Hoja2')\n",
    "X=data.drop(['Name', 'Flash flood record'],axis=1)\n",
    "y=data['Flash flood record']\n",
    "\n",
    "skfold=StratifiedKFold(n_splits=5)\n",
    "results = cross_val_score(model, X, y, cv=skfold, scoring='r2')\n",
    "print(results.mean())\n",
    "print(results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Out Cross Validation\n",
    "Un caso especial de *K-fold cross validation* es donde k sea igual al número de observaciones. Este tipo de variación se denomina *leave-one-out cross validation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "loocv = LeaveOneOut()\n",
    "model = LinearRegression()\n",
    "results = cross_val_score(model, X, y, cv=loocv, scoring='r2')\n",
    "print(results.mean())\n",
    "print(results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra variación de *k-fold* es generar una partición aleatoria como *train-test-split*, pero repite el proceso de partición y evaluación múltiples veces como *K-fold*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7288121678315397\n",
      "0.049847359292500816\n"
     ]
    }
   ],
   "source": [
    "kfold = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1)\n",
    "model = LinearRegression()\n",
    "results = cross_val_score(model, X, y, cv=kfold, scoring='r2')\n",
    "print(results.mean())\n",
    "print(results.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
