**CURSO**: Machine Learning, Departamento de Geociencias y Medio Ambiente, Universidad Nacional de Colombia - sede Medellín\
**Profesor**: Edier Aristizábal ([evaristizabalg\@unal.edu.co](mailto:evaristizabalg@unal.edu.co){.email})\
**Credits**: The content of this notebook is based on [Coding Club](https://ourcodingclub.github.io/tutorials/brms/) by Louise Litrico, Michael Clark [parte I](https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-i/#example-data), [parte II](https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/)

# Modelos Bayesianos

## Introducción a la Estadística Bayesiana

La estadística bayesiana, inventada por el reverendo Thomas Bayes en el siglo XVIII y publicada póstumamente, introdujo un concepto revolucionario: la probabilidad condicional. Ésta permite calcular la probabilidad de un evento teniendo en cuenta que otro evento ya ha ocurrido.

Imaginemos un sorteo donde se eligen números entre 0 y 100. La probabilidad inicial de obtener un número inferior a 50 se puede calcular sin necesidad de fórmulas matemáticas complejas. Ahora supongamos que nos informan que todos los números restantes en la caja son mayores a 80. Esta nueva información modifica nuestra creencia inicial. Al tener conocimiento previo de que no hay números menores a 80, la probabilidad de obtener un número inferior a 50 se vuelve nula.

Este ejemplo ilustra la esencia del Teorema de Bayes: el conocimiento previo influye en la probabilidad de un evento. En los modelos Bayesianos, la información previa se incorpora como una distribución de probabilidades en lugar de un único valor. Esto se debe a que el "evento" se convierte en múltiples eventos posibles.

Supongamos que estudiamos la abundancia de una especie. El "evento" sería encontrar un valor específico de abundancia en un día determinado (por ejemplo, una abundancia de 50 individuos). Si medimos la abundancia mensualmente durante 5 años, obtendríamos 60 valores de abundancia, que representan 60 "eventos" posibles. Al graficar estas medidas de abundancia y la frecuencia con la que se registraron, obtenemos una distribución de probabilidad que refleja la posibilidad de observar dichos valores.

![[Fig. Teorema de Bayes](aca)](https://ourcodingclub.github.io/assets/img/tutorials/brms/Pictures/distribution_plot.jpg)

La estadística Bayesiana ofrece una alternativa a los métodos estadísticos clásicos, permitiendo incorporar conocimiento previo en el análisis de datos. Veamos los puntos clave:

-   **Datos Limitados o Sesgados:** La estadística Bayesiana resulta particularmente útil cuando los datos son limitados o están sesgados por factores como métodos de muestreo inadecuados o errores de medición.

-   **Distribuciones Previas:** El conocimiento previo se incorpora mediante distribuciones previas, las cuales representan la distribución de probabilidad inicial de los parámetros del modelo antes de observar los datos reales.

-   **Distribución Posterior:** El modelo Bayesiano combina la información de los datos y la distribución previa para generar una distribución posterior. Ésta representa una estimación actualizada de la abundancia real, teniendo en cuenta tanto los datos como el conocimiento previo.

-   **Ventaja de las Distribuciones Previas:** Al integrar conocimiento previo, la distribución posterior proporciona una estimación más precisa de los parámetros del modelo y de las relaciones que se estudian.

-   **Comparación con Métodos Clásicos:** Un modelo Bayesiano, a diferencia de métodos como la regresión lineal, no solo busca la mejor línea de ajuste entre dos variables utilizando únicamente los datos. En su lugar, el modelo Bayesiano estima la "distribución real" de los datos y proporciona el valor más probable del efecto de una variable sobre otra.

## Ejemplo datos creados

Vamos a crear algunos datos para que podamos ejecutar modelos básicos. Para hacer las cosas más interesantes, el modelo subyacente verdadero tiene covariables categóricas y continuas, interacciones, relaciones no lineales, efectos aleatorios (las observaciones están agrupadas en conglomerados) y algunas variables son colineales. Puede omitir estos detalles si no le interesan, pero tenga en cuenta que usaremos intencionalmente modelos subajustados y sobreajustados en relación con este para ver qué sucede.

```{r}
library(tidyverse)
devtools::install_github('m-clark/lazerhawk')
```

```{r}
create_data <- function(N = 1000, ng = 100, seed = 1234) {
  
  set.seed(seed)
  
  # the model matrix
  X_mm = cbind(
    # a standard binary
    binary_1 = sample(0:1, N, replace = TRUE),                      
    # a relatively rare categorical
    binary_2 = sample(0:1, N, replace = TRUE, prob = c(.05, .95)),  
    # two partly collinear numeric
    mvtnorm::rmvnorm(N,
                     mean = rep(0, 3),
                     sigma = lazerhawk::create_corr(runif(3, max = .6)))
  )
  
  X_mm = cbind(
    # intercept
    1,
    X_mm,
    # a cubic effect
    scale(poly(X_mm[,5], 3))[,2:3],
    # interaction of binary variables
    X_mm[,1]*X_mm[,2], 
    # interaction of binary 2 with numeric 1
    X_mm[,2]*X_mm[,3]
  )
  
  # add names
  colnames(X_mm) = c(
    'Intercept',
    'b1',
    'b2',
    'x1',
    'x2',
    'x3',
    'x3_sq',
    'x3_cub',
    'b1_b2',
    'b2_x1'
  )
  
  # coefficients
  beta = c(
    3.0,   # intercept
     .3,   # b1
    -.3,   # b2
     .5,   # x1
     .0,   # x2
     .3 ,  # x3 
     .3,   # x3_sq
    -.2,   # x3_cub
     .5,   # b1_b2 
    -.5    # b2_x1
  )
  
  # create target variable/linear predictor
  y = X_mm %*% beta
  
  # add random effect
  groups = sort(sample(1:ng, N, replace = T))
  
  # random effect sd = .5
  re = rnorm(ng, sd = .5)[groups]  
  
  # add re and residual noise with sd = 1
  y = y + re + rnorm(N)
  y = cbind(y, groups)
  colnames(y) = c('y', 'group')
  
  as_tibble(cbind(X_mm, y))
}
```

Si desea verificar que los parámetros se recuperan, puede ejecutar algo como lo siguiente.

```{r}
dat = create_data(N = 10000)

mod = lme4::lmer(y ~ . -group + (1|group), data.frame(dat[,-1]))

summary(mod)
```

No necesitamos muchos datos para nuestros propósitos, así que estableceremos el tamaño total de la muestra en 1000. Eliminaremos las columnas innecesarias (por ejemplo, normalmente especificaríamos interacciones a través de la fórmula en lugar de crear las columnas explícitamente) y también haremos explícitos nuestros coeficientes binarios como factores, lo que facilitará las cosas cuando queramos visualizar efectos agrupados más adelante.

```{r}
# create the primary data frame

main_df = 
  create_data(N = 1000) %>% 
  as_tibble() %>% 
  select(group, b1:x3, y) %>% 
  mutate(
    b1 = factor(b1),   # will help with visuals
    b2 = factor(b2)
  )

main_df
```

Para modelos de regresión comunes, normal o t de Student para los coeficientes (efecto fijo). Tendrá que establecer esto explícitamente si usa brms, pero rstanarm ya tendrá valores predeterminados viables.

Utilice normal/t de Student (mitad) para las varianzas (especialmente modelos jerárquicos). Los valores predeterminados suelen ser adecuados.

Comenzaremos con un modelo de regresión estándar simple que sabemos que no es adecuado. Usaremos los valores predeterminados de prior **2** y ejecutaremos muy pocas iteraciones.

```{r}
# no priors, no complexity, all default settings, few iterations
library(brms)
```

```{r}
model_start_100 = brm(
  y ~ b1 + b2 + x1 + x2 + x3, 
  data = main_df,
  iter = 100,
  verbose = F,
  seed = 123
)
```

Advertencias sobre Rhat y el tamaño efectivo de la muestra (ESS) probablemente aparecerán si usa iteraciones predeterminadas para modelos más complejos. Se refieren principalmente a la eficiencia del proceso de muestreo y a si tiene suficientes muestras para tener estimaciones de parámetros estables. Idealmente, Rhat está cerca de 1.0 y ESS es al menos un porcentaje notable del total de muestras posteriores (por ejemplo, 50%).

La solución para estas advertencias suele ser simple, simplemente deje que el modelo se ejecute durante más iteraciones más allá del calentamiento. El valor predeterminado es 2000 iteraciones, con un calentamiento de la mitad. Las iteraciones de calentamiento no se utilizan en el cálculo de las estimaciones de los parámetros, por lo que puede simplemente aumentar el número de iteraciones en relación con él, o aumentar ambas solo aumentando el argumento `iter`.

A continuación, graficamos los valores estimados en cada iteración para cada cadena, llamado gráfico de trazado, así como el gráfico de densidad de los valores de toda la cadena. A partir de esto, podríamos ver que las cosas podrían ser problemáticas (por ejemplo, querríamos gráficos de densidad más simétricos para los coeficientes de regresión), pero solo si está acostumbrado a ver estas cosas, por lo que requerirá algo de práctica.

```{r}
mcmc_plot(model_start_100, pars = c('b1', 'b2', 'x1'), type = 'combo')
```

Para tener una idea de lo que esperarías, simplemente grafica una serie de una distribución normal.

```{r}
ggplot2::qplot(x = 1:1000, y = rnorm(1000), geom = 'line')
```

```{r}
ggplot2::qplot(x = rnorm(1000), geom = 'density')
```

Otros gráficos nos permiten ver el mismo tipo de cosas desde una perspectiva diferente, o desglosar los resultados por cada cadena.

```{r}
mcmc_plot(model_start_100, type = 'areas')
```

```{r}
mcmc_plot(model_start_100, pars = c('b1', 'b2', 'x1'), type = 'violin')
```

Si bien las cosas parecen estar bien, si seleccionamos una cadena en particular, podríamos pensar lo contrario. En este caso, los coeficientes de Intercepto y b2 pueden ser problemáticos, dado que no parecen variar tanto como los demás (cadena 2, por ejemplo, pero también para otras cadenas).

```{r}
mcmc_plot(model_start_100, highlight = 2, type = 'trace_highlight')

```

Algunos sugieren mirar gráficos de rango en lugar de los gráficos de trazado tradicionales. En realidad, lo único que hemos cambiado es buscar algo "difuso" a buscar algo "aproximadamente uniforme", por lo que en mi opinión no es una gran mejora visual o intuitivamente. En general, los histogramas, que son variantes de los gráficos de barras, rara vez son una mejora para cualquier visualización. Si lo usa, puede usar un enfoque de superposición para ver si los rangos se mezclan, pero esto se parece mucho a lo que estaría buscando en un gráfico de trazado.

```{r}
mcmc_plot(model_start_100, pars = c('b1', 'b2', 'x1'), type = 'rank_hist')
```

```{r}
mcmc_plot(model_start_100, pars = c('b1', 'b2', 'x1'), type = 'rank_overlay')

```

### $\widehat{R}$

The $\widehat{R}$ statistic measures the ratio of the average variance of samples within each chain to the variance of the pooled samples across chains. If all chains are at equilibrium, these will be the same and $\widehat{R}$ will be 1.0. If the chains have not converged to a common distribution, the $\widerhat{R}$ statistic will be greater than one.

What we want: values near 1.0 (\< 1 okay) and less than 1.05

```{r}
mcmc_plot(model_start_100, type = 'rhat')
```

### Tamaño efectivo de la muestra (ESS)

El tamaño efectivo de la muestra (ESS) es una estimación del número efectivo de extracciones independientes de la distribución posterior del parámetro de interés. Debido a que las extracciones dentro de una cadena no son independientes si hay autocorrelación, el tamaño efectivo de la muestra generalmente será menor que el número total de iteraciones, pero el cálculo de este estadístico es un poco más arte que ciencia, e incluso puede ser mayor que el número de extracciones posteriores. Tenga en cuenta también que el gráfico se basa en valores ligeramente diferentes a los informados por la función de resumen de brms.

-   **ESS general:** ESS para la media/mediana (n_eff en rstanarm). Nos indica si las estimaciones de los parámetros son estables.
-   **ESS de cola:** ESS para los percentiles 5% y 95%. Nos indica si las estimaciones de intervalo para los parámetros son estables. El ESS de cola puede ayudar a diagnosticar problemas debido a las diferentes escalas de las cadenas y la mezcla lenta en las colas.

Lo que queremos: ESS \> 10% del total de muestras posteriores con seguridad, pero \> 50% es lo mejor. Se desea al menos 100 para estimaciones decentes de autocorrelación. Para ESS general queremos \> 100 veces el número de cadenas.

```{r}
mcmc_plot(model_start_100, type = 'neff')  # < .1 problem
```

### Gráfico de trazado

Muestra los valores estimados de los parámetros en cada iteración. En general, te gustaría un rebote aleatorio alrededor de un valor promedio.

```{r}
mcmc_plot(model_start_100, type = 'trace')

```

Lo que queremos: Algo así como extracciones normales aleatorias a lo largo de una serie. Los gráficos de trazado en general deberían verse "herbosos" o como una "oruga difusa", lo que quizás no sea muy descriptivo, pero las desviaciones suelen ser llamativas y obvias en mi experiencia. Si ve cadenas que parecen atascarse en ciertas estimaciones o separarse unas de otras, esto indicaría un problema grave. Si las cadenas no convergen entre sí, probablemente ya esté recibiendo advertencias y mensajes.

### Gráfico de densidad

Muestra la densidad de las extracciones posteriores para los parámetros.

```{r}
mcmc_plot(model_start_100, type = 'dens')

```

Lo que queremos: Para los gráficos de densidad de los coeficientes de regresión, estos deberían verse aproximadamente normales. Para los parámetros de varianza, puede observar asimetría, especialmente si la estimación es relativamente cercana a cero con conjuntos de datos más pequeños. En general, no querríamos ver colas largas o bimodalidad para los parámetros típicos de interés con modelos que estaría haciendo con rstanarm y brms.

### Gráfico de rango

Según el archivo de ayuda de bayesplot:

Si bien los gráficos de trazado tradicionales visualizan cómo se mezclan las cadenas a lo largo del muestreo, los histogramas de rango visualizan cómo los valores de las cadenas se mezclan entre sí en términos de clasificación. Un gráfico ideal mostraría las clasificaciones mezclándose o superponiéndose en una distribución uniforme.

```{r}
mcmc_plot(model_start_100, type = 'rank_hist')

```

### Gráfico ACF (autocorrelación)

El gráfico de la función de autocorrelación (ACF), es exactamente lo mismo que visualizarías para cualquier serie de tiempo. Es un gráfico de una serie de correlaciones de un parámetro con retardos específicos de sí mismo. La autocorrelación no sesga las estimaciones, pero una mayor autocorrelación puede sugerir una exploración del espacio de parámetros más ineficiente/lenta. En el rezago cero, las estimaciones de la serie están perfectamente correlacionadas consigo mismas, por lo que ahí es donde suele comenzar el gráfico.

Lo que queremos: Una caída rápida, pero no es realmente tan importante. Para cuando descubras que es un problema, tu modelo ya se ha ejecutado.

```{r}
mcmc_plot(model_start_100, type = 'acf')
```

### Solución para advertencias Rhat/ESS

En resumen, la solución general para las advertencias de Rhat y ESS es simplemente hacer más iteraciones (en relación con el calentamiento). Para evitar que las muestras posteriores y los objetos del modelo se vuelvan demasiado grandes, considere también el adelgazamiento. El adelgazamiento solo guarda una cantidad selecta de las muestras posteriores disponibles. Por ejemplo, establecer thin = 10 significa que solo se guardará una muestra de cada diez. Esto también reducirá la autocorrelación, ya que las extracciones retenidas después del adelgazamiento no estarán tan correlacionadas entre sí como lo estarían las extracciones sucesivas. Sin embargo, si adelgaza demasiado, es posible que no tenga suficiente para el tamaño efectivo de la muestra.

```{r}
# default with 4 chains, 1000 warmup 2000 total = 4*(2000 - 1000) = 4000 post-warmup draws
#brm(model_start_100)

# 4*(4000 - 2000) = 8000 posterior draws
brm(model_start_100, warmup = 2000, iter = 4000)

# 4*(4000 - 2000)/8 = 1000 posterior draws
brm(model_start_100, warmup = 2000, iter = 4000, thin = 8)
```

### BFMI bajo

Es posible que vea una advertencia que diga que algunas cadenas tenían una "fracción bayesiana estimada de información faltante (BFMI)" demasiado baja. Esto implica que la fase de adaptación de las cadenas de Markov no funcionó bien, y es probable que esas cadenas no exploraran la distribución posterior de manera eficiente. Para obtener más detalles sobre este diagnóstico, puede consultar el artículo de Betancourt, pero esto seguramente será demasiado técnico para muchos usuarios aplicados e incluso más avanzados.

En este caso, el problema aquí a menudo se soluciona simplemente agregando más iteraciones. Normalmente me quedo con 1000 muestras posteriores, lo que permite visualizaciones más agradables de las distribuciones sin crear objetos de modelo relativamente grandes. Sin embargo, es posible que necesite más para obtener un resultado satisfactorio.

```{r}
model_start = update(
  model_start_100,
  warmup = 2000,
  iter = 2250,      # 1000 posterior draws
  cores = 4,
  seed = 123
) 
```

En este caso, ya no tenemos advertencias, e incluso uno de nuestros coeficientes más problemáticos ahora se ve bien.

```{r}
summary(model_start)
```

```{r}
plot(model_start, par = 'b2')
```

Profundidad del árbol (Máxima profundidad del árbol) es una advertencia más técnica relacionada con los detalles del algoritmo Monte Carlo Hamiltoniano (HMC). En términos prácticos:

La falta de convergencia y alcanzar el número máximo de pasos leapfrog (equivalentemente la profundidad máxima del árbol) indican posteriors inapropiados \~ Guía del usuario de Stan

A veces obtendrá una advertencia sobre alcanzar la profundidad máxima del árbol y, sin entrar en demasiados tecnicismos, la solución es bastante simple. Solo tienes que establecer un máximo más alto.

Para aumentar el valor predeterminado de 10, use el argumento `control` en la función brms.

```{r}
model_update_treedepth = update(
  model_start,
  control = list(max_tree_depth = 15)
)
```

### Transiciones divergentes

Las transiciones divergentes son un problema técnico que indica que algo puede estar notablemente mal con los datos o el modelo (detalles técnicos). Indican que el proceso de muestreo se ha "descarrilado" y que los resultados de la iteración divergente, y cualquier cosa basada en ellos (es decir, extracciones posteriores, estimaciones de parámetros), no son confiables. A diferencia de los otros problemas que hemos discutido, este es más difícil de abordar.

¿Por qué podría pasar esto?

-   Datos insuficientes para la complejidad del modelo
-   Modelo deficiente
-   Alta colinealidad
-   Priores impropios o problemáticos
-   Separabilidad (regresión logística)
-   Cualquier otra cantidad de razones

Como ejemplo, crearé un modelo demasiado complejo con solo una muestra aleatoria pequeña de los datos, usaré priores impropios y utilizaré muy pocos calentamientos/iteraciones.

```{r}
model_problem = brm(
  bf(
    y ~ b1*b2*x1 + x2*b2 + x3*b2 + (1 + x1 + b2|group),
    sigma ~ x1 + b1*b2
  ),
  data   = main_df %>% slice_sample(prop = .1),
  family = student,
  cores  = 4,
  warmup = 5,
  iter   = 1005,
  thin   = 4,
  seed   = 123
)
```

## ¿Qué hacer en caso de Transiciones Divergentes?

Empecemos por la inspección visual.

### Visualización: Diagrama de pares

Una herramienta de diagnóstico que se sugiere típicamente para observar las transiciones divergentes es el diagrama de pares (pairs plot). Es simplemente una matriz de gráficos de dispersión de las estimaciones de los parámetros (y el valor del logaritmo posterior), pero tiene algunos problemas. El gráfico tarda en renderizarse incluso con pocos parámetros y, simplemente, es demasiado complejo para usarse en muchas situaciones típicas de modelado. Si de alguna manera supiera de antemano qué parámetros están causando problemas, podría delimitarlo observando solo esos parámetros. Pero si supiera cuáles son los parámetros problemáticos, no necesitaría el diagrama de pares.

Otro problema es que no es lo que parece a primera vista. La diagonal superior no es solo las coordenadas invertidas de la diagonal inferior como cualquier otra matriz de dispersión que haya visto. Las cadenas se dividen de manera que la mitad se usa para los gráficos de la diagonal superior y la otra para la inferior, y la división se basa en la cantidad de error numérico (por encima o por debajo de la mediana). Sospecho que esto puede no ayudar a los usuarios aplicados a interpretar las cosas, pero la idea es que si sus puntos rojos solo aparecen en la diagonal superior, cambiar la parte `adapt_delta` del argumento `control` puede ayudar (ver más abajo), de lo contrario probablemente no lo hará [4].

De todos modos, echemos un vistazo al diagrama de pares. Usaré bins hexagonales en lugar de puntos estándar porque los gráficos de puntos no tienen transparencia por defecto. Además, usaremos un gráfico de densidad en la diagonal, en lugar del histograma.

```{r}
mcmc_plot(
  model_problem,
  variable = c('b_b11', 'b_b21', 'b_x1'),
  type = 'pairs',
  diag_fun = 'dens',
  off_diag_fun = 'hex',
  fixed = TRUE
)
```

En casos problemáticos, lo que podría ver en los gráficos fuera de la diagonal es una especie de "embudo", lo que indicaría dónde el muestreador se está atascando en el espacio de parámetros. Sin embargo, esta noción visual no está bien definida, ya que puede estar sucediendo sin ser obvia, mostrando solo una protuberancia o algunos patrones extraños como los anteriores. Pero también verá regularmente parámetros correlacionados, pero no está claro si estos podrían ser necesariamente un problema en una situación determinada.

Para el modelo inicial que ejecutamos, el diagrama de pares para todos los parámetros tarda varios segundos en producirse, e incluso con la opción hexagonal, sigue siendo difícil de analizar sin una inspección más cercana. Muestra que los parámetros de intercepción y b2 están notablemente correlacionados, posiblemente indirectamente debido a los priores deficientes.

```{r}
mcmc_plot(
  model_start_100,
  type = 'pairs',
  off_diag_fun = 'hex',
  diag_fun = 'dens'
)
```

Lo que buscamos: Poca correlación entre parámetros, densidades mayormente simétricas para parámetros de regresión típicos.

### Visualización: Diagrama de Coordenadas Paralelas

También se sugiere observar diagramas de coordenadas paralelas, pero desafortunadamente estos gráficos también tienen problemas. El orden del eje de variables/parámetros es arbitrario, y sin embargo, el orden definitivamente puede influir en su percepción de cualquier patrón. Además, a menos que todo esté en escalas similares, simplemente no serán muy útiles, pero incluso si escala sus datos de alguna manera, las estimaciones dadas las transiciones divergentes pueden estar notablemente más allá de una escala razonable.

Al igual que en nuestro diagrama de pares, estaríamos buscando un patrón entre las divergencias, específicamente una concentración para un parámetro donde las líneas aparentemente convergen a un punto. Si este no es el caso, las divergencias probablemente sean falsos positivos [5]. Tuve que agregar algunas opciones de ggplot para ayudar a que esto sea más legible, y probablemente usted también tendrá que hacerlo. En el siguiente ejemplo, podría pensar que el coeficiente `b_sigma_x1` para la dispersión es un problema, lo que podría sugerir que necesitamos repensar el prior para él. En realidad, es probable que solo se esté estimando que sea cercano a cero, como debería ser, especialmente porque las transiciones no divergentes también están rebotando alrededor de ese valor. En su mayor parte, no vemos mucho patrón aquí.

```{r}
mcmc_parcoord(
  model_problem,
  pars = vars(matches('^b')),
  size = .25, 
  alpha = .01,
  np = nuts_params(model_problem),  # without this div trans won't be highlighted
  np_style = parcoord_style_np(
    div_color = "#ff5500",
    div_size = 1,
    div_alpha = .1
  )
) +
  guides(x = guide_axis(n.dodge = 2)) +
  theme(
    axis.text.x = element_text(size = 6),
    panel.grid.major.x = element_line(color = '#00AAFF80', size = .1)
  )
```

## Solución para Transiciones Divergentes

Desafortunadamente, la solución a las transiciones divergentes no suele ser sencilla. El punto de partida típico para resolver el problema de las transiciones divergentes es usar el argumento `control` para aumentar `adapt_delta`, por ejemplo, de 0.80 a 0.99 [6], y dejar que su modelo tenga más calentamientos/iteraciones totales, que es el problema principal aquí. En los casos que veo para mí y para los clientes, aumentar `adapt_delta` rara vez ayuda, pero no está de más intentarlo. A menudo comenzaré con un aumento para modelos más complejos, solo para ahorrarme problemas más adelante.

```         
model = brm(..., control = list(adapt_delta = .99))
```

Aparte de eso, tendrá que profundizar más, incluidos los problemas con los priores, la especificación del modelo y más. Encuentro que este problema a menudo proviene de datos deficientes (por ejemplo, no escalados, posible separación en modelos logísticos, etc.), combinados con un modelo complejo (por ejemplo, estructura de efectos aleatorios complicada), y más allá de eso, es posible que deban modificarse los priores. Al menos no debe tener priores uniformes para ningún parámetro, y como veremos en la Parte II, puede usar un enfoque de simulación para ayudar a elegir mejores priores. A menudo, estas comprobaciones de datos y priores son un mejor enfoque para resolver el problema que hacer algo después del hecho. También es posible que deba simplificar el modelo para adaptarse mejor a los matices de sus datos. Por ejemplo, para modelos mixtos, es posible que algunos componentes de varianza no sean necesarios.

Algunas soluciones ofrecidas en los foros suponen que está codificando directamente en Stan, como reparametrizar su modelo, usar tipos específicos de priores, etc. Si está escribiendo código Stan en lugar de usar un paquete de modelado, definitivamente necesita revisarlo doblemente, ya que los errores tipográficos u otros errores ciertamente pueden resultar en un modelo problemático. Sin embargo, esta publicación está dirigida a aquellos que utilizan paquetes de modelado, por lo que no ofreceré tales remedios, y por lo general no son obvios de todos modos.

## Ejemplo 2

```{r}
# create the primary data frame

main_df = 
  create_data(N = 1000) %>% 
  as_tibble() %>% 
  select(group, b1:x3, y) %>% 
  mutate(
    b1 = factor(b1),   # will help with visuals
    b2 = factor(b2)
  )
```

Un buen paso inicial en el análisis bayesiano es pensar y producir algunos priores viables para los parámetros. Pero la pregunta obvia es, ¿qué priores deberíamos elegir? Afortunadamente, para modelos estándar no hay mucha necesidad de adivinar. El análisis bayesiano existe desde hace mucho tiempo, por lo que la mayor parte del trabajo para determinar los priors adecuados para modelos estándar ya se ha hecho por usted. Incluso las configuraciones predeterminadas no deberían afectar mucho las cosas, especialmente para rstanarm, que tiene algunos valores predeterminados básicos informados por los datos. Sin embargo, debido a la flexibilidad de las funciones de modelado brms, algunos priors no se especifican y se dejan "planos" (es decir, uniformes), lo cual es algo que definitivamente no queremos. E incluso los valores predeterminados aún podrían causar problemas en situaciones más complejas. Entonces, ¿cómo podemos elegir mejores?

La idea básica aquí es generar parámetros (por ejemplo, coeficientes de regresión) basados en sus distribuciones prioritarias correspondientes, predecir datos basados en esos sorteos previos y luego comparar las predicciones con nuestra variable objetivo observada que estamos tratando de comprender.

Afortunadamente, el paquete brms facilita mucho esto. Verificaremos los siguientes tipos de priores, que van desde configuraciones predeterminadas hasta especificaciones crecientes para todos los parámetros de interés.

```{r}
# essentially the same as the defaults
pr_uniform = prior(uniform(-100, 100), lb = -100, ub = 100, 'b')

model_default_prior = brm(
  y ~ b1 + b2 + x1 + x2 + x3, 
  data = main_df,
  iter = 1000,
  sample_prior = 'only',
  prior = pr_uniform
)

# pp_check(model_default_prior, nsamples = 50)

# diffuse normal for reg coefficients 'b'
pr_norm_b_0_10 = prior(normal(0, 10), 'b')

model_0_norm_b_0_10 = brm(
  y ~ b1 + b2 + x1 + x2 + x3, 
  data = main_df,
  iter = 1000,
  sample_prior = 'only',
  prior = pr_norm_b_0_10
)

# pp_check(model_0_norm_b_0_10, nsamples = 50)

# rstanarm-like prior
pr_auto = sjstats::auto_prior(
  y ~ b1 + b2 + x1 + x2 + x3,
  data = main_df,
  gaussian = TRUE
)

model_auto_prior = brm(
  y ~ b1 + b2 + x1 + x2 + x3, 
  data = main_df,
  iter = 1000,
  sample_prior = 'only',
  prior = pr_auto
)

# pp_check(model_auto_prior, nsamples = 50)

# Since we have standardized data, Normal(0, 1) is reasonable for reg coefs
pr_norm_b_0_1 = prior(normal(0, 1), 'b')

model_0_norm_b_0_1 = brm(
  y ~ b1 + b2 + x1 + x2 + x3, 
  data = main_df,
  iter = 1000,
  sample_prior = 'only',
  prior = pr_norm_b_0_1
)

# pp_check(model_0_norm_b_0_1, nsamples = 50)

# Now we add one for the intercept based on the mean of y
pr_norm_b_norm_int = c(
  prior(normal(0, 1), class = 'b'),
  prior(normal(3, 1), class = 'Intercept')
)

model_0_norm_b_0_1_norm_Int = brm(
  y ~ b1 + b2 + x1 + x2 + x3, 
  data = main_df,
  iter = 1000,
  sample_prior = 'only',
  prior = pr_norm_b_norm_int
)

# pp_check(model_0_norm_b_0_1_norm_Int, nsamples = 50)

# Now add a prior for sigma based on the sd of y
pr_norm_b_norm_int_t_sigma = c(
  prior(normal(0, 1), class = 'b'),
  prior(normal(3, 1), class = 'Intercept'),
  prior(student_t(10, 1, 1), class = 'sigma') # first value is deg of freedom
)

model_0_norm_b_0_1_norm_Int_sigma = brm(
  y ~ b1 + b2 + x1 + x2 + x3, 
  data = main_df,
  iter = 1000,
  sample_prior = 'only',
  prior = pr_norm_b_norm_int_t_sigma
)

# pp_check(model_0_norm_b_0_1_norm_Int_sigma, nsamples = 50)
```

El siguiente gráfico muestra las predicciones del modelo basadas únicamente en los priors. Restringimos el rango de valores para fines de visualización, por lo que tenga en cuenta que algunos de estos ajustes en realidad generarían resultados más extremos. Por ejemplo, la configuración predeterminada del prior podría generar valores en ±500 y más allá. También marco los límites de la variable objetivo observada con las líneas verticales.

![[Fig.]()](https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/practical-bayes-part-ii_files/figure-html5/proposed-priors-plot-1.svg)

Podemos ver en la visualización que el lado izquierdo que usa valores predeterminados o priors notablemente difusos da como resultado rangos sin sentido para nuestra variable objetivo. Cuando realmente ejecutamos el modelo, esto significa que exploraríamos valores de parámetros posibles (el espacio de) que no serán útiles para la predicción. Probablemente aún deberíamos llegar a las mismas conclusiones, es solo que podríamos necesitar muchas más iteraciones, y como sabemos de la Parte I, no tener suficientes iteraciones puede generar muchas advertencias.

Entonces, dado que nuestra variable objetivo está entre -2 y 8, parece que agregar solo información básica basada en datos a nuestros priors dio como resultado resultados más plausibles. Esto generalmente ayudará a que nuestros modelos sean más eficientes y se comporten mejor. Tenga en cuenta que si todo lo demás falla, puede usar una función auxiliar como `auto_prior` que se demostró anteriormente.

Ahora ejecutemos un modelo base, que sea simple pero plausible. Dado que eventualmente se agregarán otras complejidades al modelo, seguiré adelante y agregaré algunas iteraciones, y aumentaré `adapt_delta` y `max_treedepth` ahora para que el código sea reutilizable.

Tenga en cuenta que evité traducir literalmente los nombres de los argumentos (`adapt_delta` y `max_treedepth`) porque es probable que un usuario de brms en español ya esté familiarizado con ellos en inglés.

```{r}
pr = c(
  prior(normal(0, 1), class = 'b'),
  prior(student_t(10, 1, 1), class = 'sigma'),
  prior(student_t(10, 1, 1), class = 'sd')  # prior for random intercept std dev
)

model_baseline = brm(
  y ~ b1 + b2 + x1 + x2 + x3 + (1 | group), 
  data    = main_df,
  warmup  = 5000,
  iter    = 6000,
  thin    = 4,
  prior   = pr, 
  cores   = 4,
  seed    = 1234, 
  control = list(
    adapt_delta   = .95,
    max_treedepth = 15
  ),
  save_pars = save_pars(all = TRUE)  # potentially allows for more  more post-processing functionality
)
summary(model_baseline)
```

```{r}
mcmc_plot(model_baseline, type = 'areas')
```

Aunque hicimos un trabajo previo para seleccionar nuestras distribuciones prioritarias, aún podríamos estar preocupados por la influencia de nuestras opciones. Entonces, ¿cómo podemos verificar si nuestros priors fueron informativos? Lo siguiente usa el paquete `bayestestR` para hacer una simple verificación de si la desviación estándar posterior es mayor al 10% de la desviación estándar previa [2]. Tener un prior informativo no es realmente un problema en mi opinión, a menos que sea más informativo de lo que deseaba. Por ejemplo, la contracción de un coeficiente hacia cero generalmente ayudará a evitar el sobreajuste.

```{r}
prior_summary(model_baseline)
```

```{r}
bayestestR::check_prior(model_baseline)
```

Estos resultados sugieren que nuestros priors podrían ser más informativos, pero para la intercepción, por la cual no estamos muy preocupados, y para el factor que está altamente desbalanceado (b2), pero que no tiene una solución obvia. Personalmente, estaría satisfecho con este resultado, especialmente porque tomamos cuidado inicial al elegir estos priors. Si realmente lo deseara, podría cambiar los priors que resultaron informativos.

## Ejemplor datos reales

```{r}
# Load the data
France <- read_csv(url("https://raw.githubusercontent.com/ourcodingclub/CC-brms/main/Data/red_knot.csv"))
```

```{r}
head(France)  # to get the first observations in each column
str(France)  # what type of variables do we have
```

```{r}
(hist_france <- ggplot(France, aes(x = pop)) +
    geom_histogram(colour = "#8B5A00", fill = "#CD8500") +
    theme_bw() +
    ylab("Count\n") +
    xlab("\nCalidris canutus abundance") +  # latin name for red knot
    theme(axis.text = element_text(size = 12),
          axis.title = element_text(size = 14, face = "plain")))              
```

```{r}
unique(France$year)
```

## Código para el Modelo Bayesiano con brms

El código que se muestra a continuación define un modelo bayesiano utilizando el paquete `brms` en R para analizar la abundancia de la especie en función del año.

```{r}
# Especifica la fórmula del modelo
model <- brms::brm(
  formula = pop ~ I(year - 1975),  # Variable dependiente ~ variable predictora
  family = poisson, # Distribución de la variable dependiente (Poisson)
  data = France,    # Datos del marco de datos France
  iter = 4000,      # Número de iteraciones (ajustar según el tiempo de ejecución)
  warmup = 1000,    # Número de iteraciones de calentamiento a descartar
  chains = 4        # Número de cadenas independientes
)
```

**Explicación del código:**

-   `brms::brm`: Se utiliza la función `brm` del paquete `brms` para definir el modelo bayesiano.
-   `formula = pop ~ I(year - 1975)`: Esta fórmula especifica la relación entre la variable dependiente (`pop`) y la variable predictora (`year`). La función `I(year - 1975)` transforma la variable `year` para que comience en 1 (entero).
-   `family = poisson`: Se indica que la distribución de la variable dependiente (`pop`) es poisson, de acuerdo con el análisis previo.
-   `data = France`: Se especifica el marco de datos `France` que contiene los datos para el análisis.
-   `iter = 4000`: Define el número de iteraciones que ejecutará el modelo. Un número mayor de iteraciones puede mejorar la precisión pero también incrementará el tiempo de ejecución. Ajuste este valor según la potencia de cómputo disponible.
-   `warmup = 1000`: Define el número de iteraciones iniciales que se descartarán para garantizar que el modelo converge a una distribución posterior estable, libre de la influencia de los valores aleatorios iniciales.
-   `chains = 4`: Define el número de cadenas independientes que se ejecutarán para explorar el espacio de parámetros del modelo. Esto ayuda a obtener una estimación más robusta de la distribución posterior.

**Tenga en cuenta:**

-   En este ejemplo, no se ha especificado una distribución previa explícitamente. La función `brm` utiliza una distribución previa predeterminada que es relativamente no informativa (uniforme), lo que significa que tendrá un impacto mínimo en los resultados. Esto se usa cuando no se cuenta con información previa sobre los parámetros del modelo.
-   La transformación `log` se aplica internamente a los datos de conteo cuando se utiliza la familia `poisson`. Tenga esto en cuenta al interpretar los resultados del modelo.

```{r}
summary(model)
# fixef(france1_mbrms) # to get more detailed values for estimates
# coef(model_name) # if you have group-level effects (hierarchical data)
```

La salida del modelo `brm` generado por el código anterior puede parecer confusa en un principio. Sin embargo, a continuación se explica cómo interpretar la información más importante:

**Resumen del Modelo:**

La parte superior del resumen simplemente muestra un resumen del modelo ejecutado. Sirve como recordatorio de la configuración del modelo (fórmula, distribución, etc.).

**Efectos a Nivel de Población:**

La sección "Population-Level Effects" (Efectos a Nivel de Población) proporciona información clave sobre los efectos de las variables predictoras en la variable dependiente.

-   **Estimate (Estimación):** Representa la media de la distribución posterior para cada variable predictora. En términos de regresión lineal, estos valores pueden interpretarse como el intercepto y la pendiente de la relación entre las variables.
-   **Est.Error (Error Estándar):** Representa el error asociado con las estimaciones (similar al error estándar en la regresión lineal).
-   **95% Credibility Interval (CI) - Intervalo de Credibilidad del 95%:** Este intervalo indica el rango dentro del cual se encuentra el 95% de los valores de la distribución posterior.

**Interpretación del Intervalo de Credibilidad:**

-   **Efecto Significativo:** Si el intervalo de credibilidad del 95% no incluye el valor 0 y es estrictamente positivo o negativo, podemos inferir que el efecto de la variable predictora es significativo (positivo o negativo, respectivamente).
-   **Efecto No Significativo:** Si el intervalo de credibilidad del 95% incluye el valor 0, entonces no podemos afirmar con certeza que el efecto sea distinto de 0 (efecto no significativo).
-   **Intervalo Estrecho:** Un intervalo de credibilidad más estrecho indica una estimación del efecto más precisa.

En el ejemplo que estamos siguiendo, el intervalo de credibilidad del 95% para la pendiente (efecto del año) no incluye el valor 0 y es estrictamente positivo. Esto sugiere que el año tiene un efecto significativamente positivo sobre la abundancia del nudo rojo.

**Tenga en cuenta:**

-   La naturaleza estocástica de la estadística bayesiana implica que cada vez que se ejecuta (o re-ejecuta) un modelo, la salida puede variar ligeramente. Por lo tanto, incluso si utiliza los mismos efectos en su modelo, los resultados podrían diferir un poco de los que se muestran aquí. No se preocupe si sus resultados no coinciden exactamente con el ejemplo.

## Evaluación del Ajuste del Modelo Bayesiano con brms

Una vez que tenemos los resultados del modelo bayesiano generado por `brm`, es importante evaluar su convergencia y ajuste a los datos.

**Resumen del Modelo y Valores de Diagnóstico:**

El resumen del modelo que vimos anteriormente proporciona cierta información sobre el ajuste del modelo:

-   **Bulk_ESS y Tail_ESS:** Estas medidas representan el tamaño muestral efectivo para cada parámetro. Para un ajuste adecuado, se recomienda que estos valores sean superiores a 1000, lo cual parece cumplirse en este caso.
-   $\widehat{R}$ Este valor indica la potencial escala de reducción de la varianza entre cadenas. Idealmente, $\widehat{R}$ debería ser cercano a 1 para cada efecto, lo que sugiere una buena convergencia del modelo.

**Comprobación de Convergencia con gráficos:**

Otra forma de evaluar la convergencia del modelo es utilizar la función `plot` del paquete `brms`. Esta función genera varios gráficos de diagnóstico que permiten visualizar el comportamiento de las cadenas durante el proceso de simulación.

**Ejemplos de Gráficos de Diagnóstico:**

-   **Trace plots:** Muestran el recorrido de los estimadores de los parámetros a lo largo de las iteraciones de la simulación. Un trazado bien mezclado indica una adecuada exploración del espacio de parámetros.
-   **Density plots:** Representan la distribución a posteriori de cada parámetro estimado.

**Interpretación de los Gráficos:**

Un conjunto completo de gráficos de diagnóstico puede ayudar a identificar problemas de convergencia o ajuste del modelo. Por ejemplo, si los trace plots muestran un comportamiento errático o las density plots son muy estrechas o anchas, podría ser necesario aumentar el número de iteraciones o reevaluar la especificación del modelo.

En resumen, la evaluación del ajuste del modelo bayesiano implica analizar tanto los valores de diagnóstico en el resumen (`Bulk_ESS`, `Tail_ESS`, `Rhat`) como los gráficos de diagnóstico generados por la función `plot` de `brms`. Un análisis conjunto de esta información permite garantizar la fiabilidad de los resultados obtenidos.

```{r}
plot(model)
```

## Visualizando la Convergencia del Modelo Bayesiano con brms

La función `plot` del paquete `brms` permite generar gráficos de diagnóstico para evaluar la convergencia del modelo bayesiano. Estos gráficos facilitan la visualización del comportamiento de las cadenas durante el proceso de simulación.

**Ejemplo de Gráfico:**

El ejemplo que se muestra a continuación corresponde a un gráfico de trazas o "caterpillar plots" generado por la función `plot` de `brms`.

**Interpretación del Gráfico de Trazas:**

-   **Caterpillar Plot:** Idealmente, el trazado debe mostrar un comportamiento similar a una "oruga difusa" o a un "brillante de fiesta". Esto indica que el modelo exploró adecuadamente el espacio de parámetros durante las iteraciones.
-   **Eje X:** Representa las iteraciones realizadas después del calentamiento (en este caso, 2000 iteraciones, ya que se descartaron 1000 del calentamiento).
-   **Eje Y:** Muestra los valores del promedio de la distribución posterior evaluados por el modelo durante las iteraciones.
-   **Convergencia Adecuada:** Un "caterpillar plot" bien mezclado sugiere una buena convergencia del modelo.

**Gráfico de Densidad:**

El gráfico de densidad ubicado a la izquierda del "caterpillar plot" muestra la distribución de los valores medios de la distribución posterior.

-   **Eje X:** Representa los valores del promedio de la distribución posterior.
-   **Eje Y:** Indica la frecuencia con la que el modelo obtuvo cada valor del promedio.
-   **Media de la Densidad:** La media de este gráfico de densidad representa el valor promedio más probable estimado por el modelo.
-   **Comparación con la Estimación:** Idealmente, la media de la densidad debe estar muy cerca del valor estimado que se muestra en el resumen del modelo.

**Ejemplo:**

En el ejemplo que se muestra, el gráfico superior corresponde al intercepto. El gráfico de densidad asociado parece centrarse alrededor de 8.70, que es el valor estimado obtenido en el resumen del modelo. Esto sugiere una buena convergencia del modelo.

El segundo gráfico que desea ver es el gráfico pp_check. El uso principal de esta función es comprobar si su modelo predice sus datos con precisión (utilizando las estimaciones). Si es así, entonces puede utilizar ese modelo para generar nuevos datos y hacer predicciones precisas.

```{r}
pp_check(model)  # posterior predictive checks
```

Las delgadas líneas de color azul claro en este gráfico representan 10 sorteos o distribuciones aleatorias creadas por el modelo (puede aumentar esto incluyendo ndraws = 100 en el código). La línea azul oscuro representa la distribución posterior (que se considera que se ajusta bien a nuestros datos, por lo que puede usarse para comparar las predicciones del modelo con la realidad). Como puede ver aquí, las dos distribuciones son similares, por lo que todo está bien.

## Incorporando Efectos Aleatorios en el Modelo Bayesiano con brms

El modelo que hemos construido hasta ahora es un modelo lineal básico con efectos fijos. Sin embargo, podemos aumentar la complejidad del modelo para tener en cuenta posibles efectos aleatorios.

**Efectos Aleatorios en Poblaciones a lo largo del Tiempo:**

En nuestro ejemplo, hemos observado un aumento general en la población del nudo rojo a lo largo de los años. Pero, ¿qué pasaría si cada año, el nivel poblacional anterior tuviera un efecto sobre el siguiente? Esto podría indicar que la población crece con variaciones aleatorias cada año, en lugar de un crecimiento continuo a lo largo de todo el período.

**brms y Efectos Aleatorios:**

El paquete `brms` permite incorporar efectos aleatorios de manera sencilla utilizando la sintaxis `+ (1| variable_aleatoria)`. En este caso, podemos usar directamente la variable "year" como variable aleatoria, ya que `brms` automáticamente convierte las variables aleatorias a factores.

**Ejemplo:**

```{r}
france2_mbrms <- brms::brm(
  formula = pop ~ I(year - 1975) + (1 | year),  # Se incluye el efecto aleatorio year
  family = poisson,
  data = France,
  iter = 4000,
  warmup = 1000,
  chains = 4
)

summary(france2_mbrms)
plot(france2_mbrms)
```

**Explicación:**

-   `+ (1 | year)`: Esta parte de la fórmula indica que se incluye un efecto aleatorio para la variable "year". El valor "1" dentro del paréntesis especifica que se trata de un intercept aleatorio (efecto aleatorio sobre la intersección).

**Efectos Aleatorios vs. Efectos Fijos:**

-   Los efectos fijos representan el efecto promedio de un predictor en la variable dependiente en toda la población.
-   Los efectos aleatorios capturan la variación entre diferentes grupos dentro de la población (en este caso, la variación entre años).

**En resumen:**

Incorporar efectos aleatorios en el modelo permite tener en cuenta la variación entre grupos dentro de la población y modelar con mayor precisión la relación entre las variables.\

```{r}
unique(France$Location.of.population)  # observations come from 2 locations
```

…podemos ver que las observaciones provienen de dos lugares diferentes: la costa atlántica y la costa del Canal, esto es algo que tendremos que tener en cuenta en nuestro modelo.

Siempre que su distribución de datos esté agrupada o separada en categorías, debe incluir esa información en su modelo para verificar si los grupos son significativamente diferentes. En nuestro caso, esas dos ubicaciones corresponden a dos cuerpos de agua diferentes, que pueden albergar diferentes números de individuos de playeros rojizos.

Si comprobamos esto trazando los datos...

```{r}
(boxplot_location <- ggplot(France, aes(Location.of.population, pop)) +
  geom_boxplot() +  # could be a significant effect between locations so should look at that
  theme_bw() +
  xlab("Location\n") +
  ylab("\nCalidris canutus abundance") +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14, face = "plain")))  
```

Como nota al margen, incluiremos la ubicación como efecto fijo porque solo tenemos 2 ubicaciones. Si deseas incluirlo como un efecto aleatorio, tu variable debe tener al menos 5 “niveles” o categorías.

El código del modelo se vería así.

```{r}
france3_mbrms <- brms::brm(pop ~ I(year - 1975) + Location.of.population,
                         data = France, family = poisson(), chains = 3,
                         iter = 3000, warmup = 1000)
summary(france3_mbrms)
plot(france3_mbrms)
pp_check(france3_mbrms)
```

## Ventajas de los Efectos Aleatorios y Evaluación del Modelo Bayesiano

Incorporar efectos aleatorios y evaluar el ajuste del modelo Bayesiano son pasos cruciales para obtener resultados fiables.

**Efectos Aleatorios y Convergencia:**

-   El ejemplo anterior demuestra que incluir efectos aleatorios puede mejorar el ajuste del modelo y su convergencia. Esto se refleja en los gráficos de diagnóstico que indican una buena exploración del espacio de parámetros.

**Efectos Aleatorios Significativos:**

-   El resumen del modelo nos indica que el efecto de la ubicación (Location.of.populationChannelCoast) es significativo. El valor estimado de -0.06 sugiere que la población de la costa del Canal tiene una abundancia significativamente menor que la población de la costa Atlántica.

**Evaluación del Ajuste del Modelo:**

-   El método leave-one-out cross validation (LOO) es otra técnica para evaluar el ajuste del modelo bayesiano. La LOO compara la capacidad predictiva de las distribuciones posteriores, de manera similar a la función `pp_check`. Un valor `elpd` más alto indica un mejor ajuste del modelo.

**Función compare=TRUE en brms:**

-   La función `brms` permite incluir el argumento `compare=TRUE` en la función `brm` para obtener una comparación automática de diferentes modelos según su `elpd`. El modelo con un `elpd` de 0 representará el que mejor se ajusta a los datos.

**Resumen:**

-   La incorporación de efectos aleatorios puede mejorar la precisión del modelo al tener en cuenta la variación entre grupos dentro de la población.
-   La evaluación del ajuste del modelo mediante gráficos de diagnóstico y métodos como LOO es fundamental para garantizar la fiabilidad de los resultados obtenidos del modelo bayesiano.

```{r}
loo(france1_mbrms,france2_mbrms, france3_mbrms, compare = TRUE)
```

## Visualizando el Modelo Bayesiano con brms

Una vez que tenemos un modelo Bayesiano ajustado, podemos generar gráficos para presentar los resultados. La gráfica principal suele representar la relación entre las variables clave (abundancia y tiempo) utilizando la línea de regresión obtenida a partir del modelo.

**Elementos del Gráfico:**

-   **Línea de Regresión:** Representa la relación promedio entre las variables según el modelo. Se calcula utilizando el intercepto y la pendiente del resumen del modelo.
-   **Intervalo de Credibilidad:** Indica el rango de valores dentro del cual se encuentra un determinado porcentaje (por ejemplo, 95%) de la distribución posterior. Refleja la confianza en la estimación de la línea de regresión.
-   **Datos Observados:** Muestra los puntos de datos originales (recuentos de abundancia) para comparar la línea de regresión con los datos reales.

**Ejemplo de Código R:**

```{r}
library(tidybayes)

(model_fit <- France %>%
    add_predicted_draws(france3_mbrms) %>%  # adding the posterior distribution
    ggplot(aes(x = year, y = pop)) +  
    stat_lineribbon(aes(y = .prediction), .width = c(.95, .80, .50),  # regression line and CI
                    alpha = 0.5, colour = "black") +
    geom_point(data = France, colour = "darkseagreen4", size = 3) +   # raw data
    scale_fill_brewer(palette = "Greys") +
    ylab("Calidris canutus abundance\n") +  # latin name for red knot
    xlab("\nYear") +
    theme_bw() +
    theme(legend.title = element_blank(),
          legend.position = c(0.15, 0.85)))
```

```{r}
 (location_fit <- France %>%
  group_by(Location.of.population) %>%
  add_predicted_draws(france3_mbrms) %>%
  ggplot(aes(x = year, y = pop, color = ordered(Location.of.population), fill = ordered(Location.of.population))) +
  stat_lineribbon(aes(y = .prediction), .width = c(.95, .80, .50), alpha = 1/4) +
  geom_point(data = France) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Dark2") +
  theme_bw() +
  ylab("Calidris canutus abundance\n") +
  xlab("\nYear") +
  theme_bw() +
  theme(legend.title = element_blank()))
```
